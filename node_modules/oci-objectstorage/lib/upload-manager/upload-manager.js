"use strict";
/**
 * Copyright (c) 2020, 2021 Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.UploadManager = void 0;
const index_1 = require("../../index");
const oci_common_1 = require("oci-common");
const await_semaphore_1 = require("await-semaphore");
const blob_factory_1 = require("./blob-factory");
/**
 * UploadManager simplifies interaction with the Object Storage service by abstracting away the method used
 * to upload objects.  Depending on the configuration parameters(UploadOptions), UploadManager may choose to do a single
 * PutObject request, or break up the upload into multiple parts and utilize multi-part uploads.
 * <p>
 * An advantage of using multi-part uploads is the ability to be able to upload parts in parallel to reduce upload time.
 * <p>
 * Callers still have full control over how the UploadManager decides to perform the upload using UploadOptions.
 * NodeJS V8 Engine have a buffer size limitation, 2GB for 64-bit machine and 1GB for 32-bit machine.
 * Do not make the partSize greater than the buffer size limitation.
 */
class UploadManager {
    constructor(client, options) {
        this.client = client;
        // uploadSize will be a dictionary that keeps track of uploadSize per uploadId. This helps prevent mismatch uploadSize with
        // different upload when uploading multiple things in parallel.
        this.uploadSize = {};
        this.options = Object.assign(Object.assign({}, UploadManager.defaultUploadOptions), options);
    }
    get logger() {
        return oci_common_1.LOG.logger;
    }
    shouldUseMultipartUpload(content) {
        return content.size > this.options.partSize;
    }
    /**
     * Initiates a new upload request.  The upload manager will decide whether to use
     * a single PutObject call or multi-part uploads depending on the UploadOptions
     * specified.
     * <p>
     * Note, if a multi-part upload attempt fails, the UploadManager will attempt to
     * abort the upload to avoid leaving partially complete uploads and parts
     * (unless explicitly disabled via uploadOptions).
     *
     * @param request The upload request.
     * @return The UploadResponse.
     * @throws OciError if the upload fails for any reason.
     */
    upload(request, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            const content = blob_factory_1.getContent(request.content, this.options);
            if (this.shouldUseMultipartUpload(content)) {
                return this.multiUpload(request.requestDetails, content, callback);
            }
            return this.singleUpload(request.requestDetails, content);
        });
    }
    singleUpload(requestDetails, content) {
        return __awaiter(this, void 0, void 0, function* () {
            const contentDetails = {
                putObjectBody: yield content.getData(),
                contentLength: content.size
            };
            const contentMD5Hash = this.options.enforceMD5
                ? { contentMD5: yield content.getMD5Hash() }
                : {};
            if (this.logger)
                this.logger.debug("uploading using single upload");
            const response = yield this.client.putObject(Object.assign(Object.assign(Object.assign({}, requestDetails), contentDetails), contentMD5Hash));
            return {
                eTag: response.eTag,
                contentMd5: response.opcContentMd5,
                opcRequestId: response.opcRequestId,
                opcClientRequestId: response.opcClientRequestId
            };
        });
    }
    triggerUploadPart(content, requestDetails, uploadId, uploadPartNum, semaphore, totalSize, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                return yield semaphore.use(() => __awaiter(this, void 0, void 0, function* () {
                    const contentDetails = {
                        uploadPartBody: yield content.getData(),
                        contentLength: content.size
                    };
                    const contentMD5Hash = this.options.enforceMD5
                        ? { contentMD5: yield content.getMD5Hash() }
                        : {};
                    const uploadPartDetails = {
                        uploadId: uploadId,
                        uploadPartNum: uploadPartNum
                    };
                    const response = yield this.client.uploadPart(Object.assign(Object.assign(Object.assign(Object.assign({}, requestDetails), uploadPartDetails), contentDetails), contentMD5Hash));
                    const uploadSize = (this.uploadSize[uploadId] += content.size);
                    const progress = (uploadSize / totalSize) * 100;
                    const result = {
                        etag: response.eTag,
                        partNum: uploadPartNum,
                        progress: progress.toFixed()
                    };
                    if (callback) {
                        callback(result);
                    }
                    return result;
                }));
            }
            catch (ex) {
                if (this.logger)
                    this.logger.error(`Upload of part: ${uploadPartNum} failed due to ${ex}`);
                throw ex;
            }
        });
    }
    multiUpload(requestDetails, content, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            const createUploadResponse = yield this.client.createMultipartUpload(Object.assign(Object.assign({}, UploadManager.composeRequestDetails(requestDetails)), { createMultipartUploadDetails: {
                    object: requestDetails.objectName,
                    storageTier: requestDetails.storageTier
                        ? requestDetails.storageTier
                        : index_1.models.StorageTier.Standard
                } }));
            const uploadId = createUploadResponse.multipartUpload.uploadId;
            this.uploadSize[uploadId] = 0;
            try {
                const totalSize = content.size;
                const partUploadPromises = new Array();
                let uploadPartNum = 1;
                const semaphore = new await_semaphore_1.Semaphore(this.options.maxConcurrentUploads);
                for (let currentChunkStart = 0; currentChunkStart < totalSize; currentChunkStart += this.options.partSize) {
                    const slicedContent = content.slice(currentChunkStart, currentChunkStart + this.options.partSize);
                    partUploadPromises.push(this.triggerUploadPart(slicedContent, requestDetails, uploadId, uploadPartNum, semaphore, totalSize, callback));
                    uploadPartNum++;
                }
                const uploadPartDetails = yield Promise.all(partUploadPromises);
                const response = yield this.client.commitMultipartUpload(Object.assign(Object.assign({}, UploadManager.composeRequestDetails(requestDetails)), { commitMultipartUploadDetails: {
                        partsToCommit: uploadPartDetails
                    }, uploadId: uploadId }));
                return {
                    eTag: response.eTag,
                    multipartMd5: response.opcMultipartMd5,
                    opcRequestId: response.opcRequestId,
                    opcClientRequestId: response.opcClientRequestId
                };
            }
            catch (ex) {
                if (this.options.isDisableAutoAbort) {
                    if (this.logger)
                        this.logger.info(`Not aborting failed multipart upload as per configuration, client must manually abort it`);
                }
                else {
                    if (this.logger)
                        this.logger.error(`Aborting multi-part upload ${uploadId}`);
                    yield this.client.abortMultipartUpload(Object.assign(Object.assign({}, UploadManager.composeRequestDetails(requestDetails)), { uploadId: uploadId }));
                    if (this.logger)
                        this.logger.error(`Abort complete`);
                }
                if (ex instanceof oci_common_1.OciError)
                    throw ex;
                throw new oci_common_1.OciError(-1, "Unknown code", `Failed to upload object using multi-part uploads due to ${ex}`, null);
            }
        });
    }
    static composeRequestDetails(requestDetails) {
        return {
            namespaceName: requestDetails.namespaceName,
            bucketName: requestDetails.bucketName,
            objectName: requestDetails.objectName,
            opcClientRequestId: requestDetails.opcClientRequestId
        };
    }
}
exports.UploadManager = UploadManager;
UploadManager.defaultUploadOptions = {
    partSize: 20 * 1024 * 1024,
    maxConcurrentUploads: 5,
    allowedMemoryUsage: 5 * 20 * 1024 * 1024,
    enforceMD5: false,
    isDisableAutoAbort: false
};
//# sourceMappingURL=upload-manager.js.map